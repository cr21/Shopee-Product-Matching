{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "060705af",
   "metadata": {
    "papermill": {
     "duration": 0.063765,
     "end_time": "2022-03-20T18:56:02.029739",
     "exception": false,
     "start_time": "2022-03-20T18:56:01.965974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Shopee-Product-Matching\n",
    "![Shopee](https://cdn.lynda.com/course/563030/563030-636270778700233910-16x9.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06064405",
   "metadata": {
    "papermill": {
     "duration": 0.046048,
     "end_time": "2022-03-20T18:56:02.142562",
     "exception": false,
     "start_time": "2022-03-20T18:56:02.096514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. If you want to learn more about this amazing competition hosted by [Shopee](https://www.kaggle.com/c/shopee-product-matching), Please visit following [Shopee EDA Image AutoEncoder](https://www.kaggle.com/code/chiragtagadiya/shopee-basic-autoencoder).\n",
    "2. This Notebook contains EDA and Image AutoEncoder solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5efd65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:02.217369Z",
     "iopub.status.busy": "2022-03-20T18:56:02.216298Z",
     "iopub.status.idle": "2022-03-20T18:56:02.236928Z",
     "shell.execute_reply": "2022-03-20T18:56:02.236236Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.109796Z"
    },
    "papermill": {
     "duration": 0.063361,
     "end_time": "2022-03-20T18:56:02.237107",
     "exception": false,
     "start_time": "2022-03-20T18:56:02.173746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c3b06",
   "metadata": {
    "papermill": {
     "duration": 0.031698,
     "end_time": "2022-03-20T18:56:02.300602",
     "exception": false,
     "start_time": "2022-03-20T18:56:02.268904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0ec132",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:02.370270Z",
     "iopub.status.busy": "2022-03-20T18:56:02.369489Z",
     "iopub.status.idle": "2022-03-20T18:56:06.769653Z",
     "shell.execute_reply": "2022-03-20T18:56:06.769101Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.127274Z"
    },
    "papermill": {
     "duration": 4.437249,
     "end_time": "2022-03-20T18:56:06.769863",
     "exception": false,
     "start_time": "2022-03-20T18:56:02.332614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timmmaster')\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c02c774e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:06.833992Z",
     "iopub.status.busy": "2022-03-20T18:56:06.833158Z",
     "iopub.status.idle": "2022-03-20T18:56:09.371775Z",
     "shell.execute_reply": "2022-03-20T18:56:09.372819Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.133216Z"
    },
    "papermill": {
     "duration": 2.574561,
     "end_time": "2022-03-20T18:56:09.373093",
     "exception": false,
     "start_time": "2022-03-20T18:56:06.798532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F \n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from datetime import date\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e20f855",
   "metadata": {
    "papermill": {
     "duration": 0.043566,
     "end_time": "2022-03-20T18:56:09.460778",
     "exception": false,
     "start_time": "2022-03-20T18:56:09.417212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebad0b5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:09.608002Z",
     "iopub.status.busy": "2022-03-20T18:56:09.607251Z",
     "iopub.status.idle": "2022-03-20T18:56:09.612187Z",
     "shell.execute_reply": "2022-03-20T18:56:09.611604Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.142977Z"
    },
    "papermill": {
     "duration": 0.106143,
     "end_time": "2022-03-20T18:56:09.612334",
     "exception": false,
     "start_time": "2022-03-20T18:56:09.506191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../input/shopee-product-matching/train_images'\n",
    "TEST_DIR = '../input/shopee-product-matching/test_images'\n",
    "TRAIN_CSV = '../input/crossvalidationfolds/folds.csv'\n",
    "MODEL_PATH = './'\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    seed = 123 \n",
    "    img_size = 512\n",
    "    classes = 11014\n",
    "    fc_dim = 512\n",
    "    epochs = 15\n",
    "    batch_size = 32\n",
    "    num_workers = 3\n",
    "    model_name = 'tf_efficientnet_b4'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    scheduler_params = {\n",
    "        \"lr_start\": 1e-3,\n",
    "        \"lr_max\": 1e-5 * batch_size,\n",
    "        \"lr_min\": 1e-6,\n",
    "        \"lr_ramp_ep\": 5,\n",
    "        \"lr_sus_ep\": 0,\n",
    "        \"lr_decay\": 0.8,\n",
    "    }\n",
    "    model_path='../input/21-mar-lr-large/2022-03-20_softmax_512x512_tf_efficientnet_b4.pt'\n",
    "    isTraining=False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e000c",
   "metadata": {
    "papermill": {
     "duration": 0.026874,
     "end_time": "2022-03-20T18:56:09.667495",
     "exception": false,
     "start_time": "2022-03-20T18:56:09.640621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Custom DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89370cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:09.731461Z",
     "iopub.status.busy": "2022-03-20T18:56:09.730454Z",
     "iopub.status.idle": "2022-03-20T18:56:09.733203Z",
     "shell.execute_reply": "2022-03-20T18:56:09.733724Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.152443Z"
    },
    "papermill": {
     "duration": 0.039202,
     "end_time": "2022-03-20T18:56:09.733958",
     "exception": false,
     "start_time": "2022-03-20T18:56:09.694756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df,root_dir, isTraining=False, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get row at index idx\n",
    "#         print(\"idx\",idx)\n",
    "        \n",
    "        row = self.df.iloc[idx]\n",
    "#         print(row)\n",
    "        label = row.label_group\n",
    "        image_path = os.path.join(self.root_dir, row.image)\n",
    "        \n",
    "        # read image convert to RGB and apply augmentation\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            aug = self.transform(image=image)\n",
    "            image = aug['image']\n",
    "        \n",
    "        return image, torch.tensor(label).long()\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b40c30",
   "metadata": {
    "papermill": {
     "duration": 0.025885,
     "end_time": "2022-03-20T18:56:09.786408",
     "exception": false,
     "start_time": "2022-03-20T18:56:09.760523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Data Augmentation For training and validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82910464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:09.848567Z",
     "iopub.status.busy": "2022-03-20T18:56:09.847678Z",
     "iopub.status.idle": "2022-03-20T18:56:09.851926Z",
     "shell.execute_reply": "2022-03-20T18:56:09.851303Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.163460Z"
    },
    "papermill": {
     "duration": 0.039193,
     "end_time": "2022-03-20T18:56:09.852077",
     "exception": false,
     "start_time": "2022-03-20T18:56:09.812884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def getAugmentation(IMG_SIZE, isTraining=False):\n",
    "    \n",
    "    if isTraining:\n",
    "        return albumentations.Compose([\n",
    "            albumentations.Resize(IMG_SIZE, IMG_SIZE, always_apply=True),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.Rotate(limit=120, p=0.75),\n",
    "            albumentations.RandomBrightness(limit=(0.09, 0.6), p=0.5),\n",
    "            albumentations.Normalize(\n",
    "                mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ])\n",
    "    else:\n",
    "        return albumentations.Compose([\n",
    "            albumentations.Resize(IMG_SIZE, IMG_SIZE, always_apply=True),\n",
    "            albumentations.Normalize(\n",
    "                mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da9b8fa",
   "metadata": {
    "papermill": {
     "duration": 0.027235,
     "end_time": "2022-03-20T18:56:09.906028",
     "exception": false,
     "start_time": "2022-03-20T18:56:09.878793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "180320ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:09.972353Z",
     "iopub.status.busy": "2022-03-20T18:56:09.971368Z",
     "iopub.status.idle": "2022-03-20T18:56:09.974283Z",
     "shell.execute_reply": "2022-03-20T18:56:09.974872Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.174995Z"
    },
    "papermill": {
     "duration": 0.042614,
     "end_time": "2022-03-20T18:56:09.975049",
     "exception": false,
     "start_time": "2022-03-20T18:56:09.932435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeLabelGroupClassfier(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                     model_name='tf_efficientnet_b0',\n",
    "                     loss_fn='softmax',\n",
    "                     classes = CFG.classes,\n",
    "                     fc_dim = CFG.fc_dim,\n",
    "                     pretrained=True,\n",
    "                     use_fc=True,\n",
    "                     isTraining=False\n",
    "                ):\n",
    "        \n",
    "        \n",
    "        super(ShopeeLabelGroupClassfier,self).__init__()\n",
    "        \n",
    "        # create bottlenack backbone network from pretrained model \n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        in_features = self.backbone.classifier.in_features\n",
    "        # we will put FC layers over backbone to classfy images based on label groups\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.use_fc = use_fc\n",
    "        self.loss_fn =loss_fn\n",
    "        \n",
    "        # build top fc layers\n",
    "        if self.use_fc:\n",
    "            self.dropout = nn.Dropout(0.2)\n",
    "            self.fc = nn.Linear(in_features,fc_dim )\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            in_features = fc_dim\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "        if self.loss_fn=='softmax':\n",
    "            self.final = nn.Linear(in_features, CFG.classes)\n",
    "    \n",
    "    def forward(self, image, label):\n",
    "        features = self.get_features(image)\n",
    "        \n",
    "        if self.loss_fn=='softmax':\n",
    "            logits = self.final(features)\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def get_features(self,inp):\n",
    "        batch_dim = inp.shape[0]\n",
    "        inp = self.backbone(inp)\n",
    "        inp = self.pooling(inp).view(batch_dim, -1)\n",
    "        if self.use_fc:\n",
    "            inp = self.dropout(inp)\n",
    "            inp = self.fc(inp)\n",
    "            inp = self.bn(inp)\n",
    "        \n",
    "        return inp\n",
    "    \n",
    "    \n",
    "# shoppe_label_classfier = ShopeeLabelGroupClassfier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701a850",
   "metadata": {
    "papermill": {
     "duration": 0.026631,
     "end_time": "2022-03-20T18:56:10.029203",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.002572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training  Single Epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3553193",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:10.091720Z",
     "iopub.status.busy": "2022-03-20T18:56:10.090961Z",
     "iopub.status.idle": "2022-03-20T18:56:10.095058Z",
     "shell.execute_reply": "2022-03-20T18:56:10.094494Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.202415Z"
    },
    "papermill": {
     "duration": 0.03995,
     "end_time": "2022-03-20T18:56:10.095193",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.055243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_one_epoch(epoch_num,model, dataloader,optimizer, scheduler, device, loss_criteria):\n",
    "    avgloss = 0.0\n",
    "    # put model in traning model\n",
    "    model.train()\n",
    "    tq = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    \n",
    "    for idx, data in tq:\n",
    "        batch_size = data[0].shape[0]\n",
    "        images = data[0]\n",
    "        targets = data[1]\n",
    "        # zero out gradient\n",
    "        optimizer.zero_grad()\n",
    "        # put input and target to device\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # pass input to the model\n",
    "        output = model(images,targets)\n",
    "        # get loss\n",
    "        loss = loss_criteria(output,targets)\n",
    "        # backpropogation \n",
    "        loss.backward()\n",
    "        # update learning rate step\n",
    "        optimizer.step() \n",
    "        # avg loss\n",
    "        avgloss += loss.item() \n",
    "\n",
    "        tq.set_postfix({'loss' : '%.6f' %float(avgloss/(idx+1)), 'LR' : optimizer.param_groups[0]['lr']})\n",
    "        \n",
    "    # lr scheduler step after each epoch\n",
    "    scheduler.step()\n",
    "    return avgloss / len(dataloader)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc482c1",
   "metadata": {
    "papermill": {
     "duration": 0.027048,
     "end_time": "2022-03-20T18:56:10.149042",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.121994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Validating Single Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6318d087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:10.211368Z",
     "iopub.status.busy": "2022-03-20T18:56:10.210360Z",
     "iopub.status.idle": "2022-03-20T18:56:10.213019Z",
     "shell.execute_reply": "2022-03-20T18:56:10.213498Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.213796Z"
    },
    "papermill": {
     "duration": 0.03866,
     "end_time": "2022-03-20T18:56:10.213663",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.175003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validation_one_epoch(model, dataloader, epoch, device, loss_criteria):\n",
    "    avgloss = 0.0\n",
    "    # put model in traning model\n",
    "    model.eval()\n",
    "    tq = tqdm(enumerate(dataloader), desc = \"Training Epoch { }\" + str(epoch+1))\n",
    "    \n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "    with torch.no_grad():\n",
    "        for idx, data in tq:\n",
    "            batch_size = data[0].shape[0]\n",
    "            images = data[0]\n",
    "            targets = data[1]\n",
    "\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(images,targets)\n",
    "            predicted_label=torch.argmax(output,1)\n",
    "            y_true.extend(targets.detach().cpu().numpy())\n",
    "            y_pred.extend(predicted_label.detach().cpu().numpy())\n",
    "            loss = loss_criteria(output,targets)\n",
    "\n",
    "            avgloss += loss.item() \n",
    "\n",
    "            tq.set_postfix({'validation loss' : '%.6f' %float(avgloss/(idx+1))})\n",
    "    f1_score_metric = f1_score(y_true, y_pred, average='micro')\n",
    "    tq.set_postfix({'validation f1 score' : '%.6f' %float(f1_score_metric)})\n",
    "    return avgloss / len(dataloader),f1_score_metric\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c870b5ad",
   "metadata": {
    "papermill": {
     "duration": 0.027844,
     "end_time": "2022-03-20T18:56:10.268606",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.240762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper Function for Handling class imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "465cf8b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:10.332982Z",
     "iopub.status.busy": "2022-03-20T18:56:10.331901Z",
     "iopub.status.idle": "2022-03-20T18:56:10.334609Z",
     "shell.execute_reply": "2022-03-20T18:56:10.335131Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.226762Z"
    },
    "papermill": {
     "duration": 0.038714,
     "end_time": "2022-03-20T18:56:10.335288",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.296574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def get_class_weights(data):\n",
    "    weight_dict=dict()\n",
    "    # Format of row : PostingId, Image, ImageHash, Title, LabelGroup\n",
    "    # LabelGroup index is 4 and it is representating class information\n",
    "    for row in data.values:\n",
    "        weight_dict[row[4]]=0\n",
    "    # Word dictionary keys will be label and value will be frequency of label in dataset\n",
    "    for row in data.values:\n",
    "        weight_dict[row[4]]+=1\n",
    "    # for each data point get label count data\n",
    "    class_sample_count= np.array([weight_dict[row[4]] for row in data.values])\n",
    "    # each data point weight will be inverse of frequency\n",
    "    weight = 1. / class_sample_count\n",
    "    weight=torch.from_numpy(weight)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92975df4",
   "metadata": {
    "papermill": {
     "duration": 0.027571,
     "end_time": "2022-03-20T18:56:10.391126",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.363555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f0dfea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:10.463896Z",
     "iopub.status.busy": "2022-03-20T18:56:10.462751Z",
     "iopub.status.idle": "2022-03-20T18:56:10.465201Z",
     "shell.execute_reply": "2022-03-20T18:56:10.465719Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.237935Z"
    },
    "papermill": {
     "duration": 0.048233,
     "end_time": "2022-03-20T18:56:10.465908",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.417675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    data = pd.read_csv('../input/crossvalidationfolds/folds.csv')\n",
    "    \n",
    "    # label encoding\n",
    "    labelencoder= LabelEncoder()\n",
    "    data['label_group_original']=data['label_group']\n",
    "    data['label_group'] = labelencoder.fit_transform(data['label_group'])\n",
    "    #data['weights'] = data['label_group'].map(1/data['label_group'].value_counts())\n",
    "    # create training_data and validation data initially not using k fold\n",
    "    train_data = data[data['fold']!=0]\n",
    "    # get weights for  classes\n",
    "    samples_weight=get_class_weights(train_data)\n",
    "    \n",
    "    print(\"samples_weight\", len(samples_weight))\n",
    "    validation_data = data[data['fold']==0]\n",
    "    \n",
    "    # training augmentation\n",
    "    train_aug = getAugmentation(CFG.img_size,isTraining=True )\n",
    "    validation_aug = getAugmentation(CFG.img_size, isTraining=False)\n",
    "    # create custom train and validation dataset\n",
    "    \n",
    "    trainset = ShopeeDataset(train_data, TRAIN_DIR, isTraining=True, transform = train_aug)\n",
    "    validset = ShopeeDataset(validation_data, TRAIN_DIR, isTraining=False, transform = validation_aug)\n",
    "    print(len(data), len(samples_weight))\n",
    "    print(len(trainset))\n",
    "    # create data sampler\n",
    "                  \n",
    "    sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, num_samples=len(samples_weight))   \n",
    "    \n",
    "    # create custom training and validation data loader num_workers=CFG.num_workers,\n",
    "    train_dataloader = DataLoader(trainset, batch_size=CFG.batch_size,\n",
    "                          drop_last=True,pin_memory=True, sampler=sampler)\n",
    "    \n",
    "    validation_dataloader = DataLoader(validset, batch_size=CFG.batch_size,\n",
    "                         drop_last=True,pin_memory=True)\n",
    "    \n",
    "    \n",
    "    # define loss function\n",
    "    loss_criteria = nn.CrossEntropyLoss()\n",
    "    loss_criteria.to(CFG.device)\n",
    "    # define model\n",
    "    \n",
    "    model = ShopeeLabelGroupClassfier()\n",
    "    model.to(CFG.device)\n",
    "    \n",
    "    # define optimzer\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr= CFG.scheduler_params['lr_start'])\n",
    "    \n",
    "    # learning rate scheudler\n",
    "    scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=7, T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
    "    \n",
    "    history = {'train_loss':[],'validation_loss':[]}\n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        # get current epoch training loss\n",
    "        avg_train_loss = training_one_epoch(epoch_num = epoch,\n",
    "                                           model = model,\n",
    "                                           dataloader = train_dataloader,\n",
    "                                           optimizer = optimizer,\n",
    "                                           scheduler = scheduler,\n",
    "                                           device = CFG.device, \n",
    "                                           loss_criteria = loss_criteria)\n",
    "        \n",
    "        # get current epoch validation loss\n",
    "        avg_validation_loss = validation_one_epoch(model = model,\n",
    "                                           dataloader = validation_dataloader,\n",
    "                                           epoch = epoch,\n",
    "                                           device = CFG.device,\n",
    "                                           loss_criteria = loss_criteria)\n",
    "        \n",
    "        \n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['validation_loss'].append(avg_validation_loss)\n",
    "        \n",
    "        # save model\n",
    "        torch.save(model.state_dict(), MODEL_PATH + str(date.today()) +'_softmax_512x512_{}.pt'.format(CFG.model_name))\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "#             'scheduler': lr_scheduler.state_dict()\n",
    "            },\n",
    "            MODEL_PATH + str(date.today()) +'_softmax_512x512_{}_checkpoints.pt'.format(CFG.model_name)\n",
    "        )\n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3973430f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:10.524178Z",
     "iopub.status.busy": "2022-03-20T18:56:10.523113Z",
     "iopub.status.idle": "2022-03-20T18:56:10.528643Z",
     "shell.execute_reply": "2022-03-20T18:56:10.528127Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.257434Z"
    },
    "papermill": {
     "duration": 0.036247,
     "end_time": "2022-03-20T18:56:10.528774",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.492527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history=None\n",
    "if CFG.isTraining:\n",
    "    model, history = run_training()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fce3e",
   "metadata": {
    "papermill": {
     "duration": 0.025752,
     "end_time": "2022-03-20T18:56:10.582664",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.556912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Plot Training and Validation Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5410426d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:10.643265Z",
     "iopub.status.busy": "2022-03-20T18:56:10.642147Z",
     "iopub.status.idle": "2022-03-20T18:56:10.644891Z",
     "shell.execute_reply": "2022-03-20T18:56:10.645355Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.264019Z"
    },
    "papermill": {
     "duration": 0.036031,
     "end_time": "2022-03-20T18:56:10.645565",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.609534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.isTraining:\n",
    "    epoch_lst = [ i+1 for i in range(15)]\n",
    "    plt.plot(epoch_lst,history['train_loss'])\n",
    "\n",
    "    plt.xlabel(\"Epoch number\")\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title('Training Loss SoftMax Loss Function')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29089595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:10.705278Z",
     "iopub.status.busy": "2022-03-20T18:56:10.704104Z",
     "iopub.status.idle": "2022-03-20T18:56:10.706543Z",
     "shell.execute_reply": "2022-03-20T18:56:10.707081Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.271952Z"
    },
    "papermill": {
     "duration": 0.035018,
     "end_time": "2022-03-20T18:56:10.707248",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.672230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.isTraining:\n",
    "    plt.plot(epoch_lst,history['validation_loss'])\n",
    "    plt.xlabel(\"Epoch number\")\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.title('Validation Loss SoftMax Loss Function')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1047209f",
   "metadata": {
    "papermill": {
     "duration": 0.026562,
     "end_time": "2022-03-20T18:56:10.760905",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.734343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe8fd1e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:10.825212Z",
     "iopub.status.busy": "2022-03-20T18:56:10.823037Z",
     "iopub.status.idle": "2022-03-20T18:56:10.828144Z",
     "shell.execute_reply": "2022-03-20T18:56:10.828644Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.280581Z"
    },
    "papermill": {
     "duration": 0.041408,
     "end_time": "2022-03-20T18:56:10.828833",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.787425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    data = pd.read_csv('../input/crossvalidationfolds/folds.csv')\n",
    "\n",
    "    # label encoding\n",
    "    labelencoder= LabelEncoder()\n",
    "    data['label_group'] = labelencoder.fit_transform(data['label_group'])\n",
    "    # Prepare Validation data\n",
    "    validation_data = data[data['fold']==0]\n",
    "    validation_aug = getAugmentation(CFG.img_size,isTraining=False)\n",
    "    validset = ShopeeDataset(validation_data, TRAIN_DIR, isTraining=False, transform = validation_aug)\n",
    "    test_data_loader = torch.utils.data.DataLoader(validset,batch_size=CFG.batch_size)\n",
    "    \n",
    "    # put model in evalution mode\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    tq = tqdm(enumerate(test_data_loader))\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "    with torch.no_grad():\n",
    "        for idx, data in tq:\n",
    "            images = data[0]\n",
    "            targets = data[1]\n",
    "            \n",
    "            images = images.to(CFG.device)\n",
    "            targets = targets.to(CFG.device)\n",
    "            y_true.extend(targets.detach().cpu().numpy())\n",
    "            output = model(images,targets)\n",
    "            outputs=torch.argmax(output,1)\n",
    "            y_pred.extend(outputs.detach().cpu().numpy())\n",
    "        \n",
    "    f1_score_metric = f1_score(y_true, y_pred, average='micro')\n",
    "    return f1_score_metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "004c9239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T18:56:10.884494Z",
     "iopub.status.busy": "2022-03-20T18:56:10.883500Z",
     "iopub.status.idle": "2022-03-20T19:00:06.430908Z",
     "shell.execute_reply": "2022-03-20T19:00:06.430263Z",
     "shell.execute_reply.started": "2022-03-20T18:49:29.292604Z"
    },
    "papermill": {
     "duration": 235.576491,
     "end_time": "2022-03-20T19:00:06.431065",
     "exception": false,
     "start_time": "2022-03-20T18:56:10.854574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "215it [03:50,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.6274452554744525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not CFG.isTraining:\n",
    "    model = ShopeeLabelGroupClassfier(pretrained=False).to(CFG.device)\n",
    "    model.load_state_dict(torch.load(CFG.model_path))\n",
    "    f1=prediction(model)\n",
    "    print(\"F1 score {}\".format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 256.528223,
   "end_time": "2022-03-20T19:00:08.363243",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-20T18:55:51.835020",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
