{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712f7b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:41.242213Z",
     "iopub.status.busy": "2022-03-20T06:20:41.240645Z",
     "iopub.status.idle": "2022-03-20T06:20:41.266950Z",
     "shell.execute_reply": "2022-03-20T06:20:41.268144Z",
     "shell.execute_reply.started": "2022-03-19T23:33:15.775327Z"
    },
    "papermill": {
     "duration": 0.0677,
     "end_time": "2022-03-20T06:20:41.268521",
     "exception": false,
     "start_time": "2022-03-20T06:20:41.200821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6c275d",
   "metadata": {
    "papermill": {
     "duration": 0.033949,
     "end_time": "2022-03-20T06:20:41.340574",
     "exception": false,
     "start_time": "2022-03-20T06:20:41.306625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29246ecf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:41.416106Z",
     "iopub.status.busy": "2022-03-20T06:20:41.411943Z",
     "iopub.status.idle": "2022-03-20T06:20:45.263860Z",
     "shell.execute_reply": "2022-03-20T06:20:45.263281Z",
     "shell.execute_reply.started": "2022-03-19T23:33:17.747291Z"
    },
    "papermill": {
     "duration": 3.889234,
     "end_time": "2022-03-20T06:20:45.263994",
     "exception": false,
     "start_time": "2022-03-20T06:20:41.374760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timmmaster')\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c41bba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:45.323477Z",
     "iopub.status.busy": "2022-03-20T06:20:45.320431Z",
     "iopub.status.idle": "2022-03-20T06:20:47.308184Z",
     "shell.execute_reply": "2022-03-20T06:20:47.307294Z",
     "shell.execute_reply.started": "2022-03-19T23:33:21.152691Z"
    },
    "papermill": {
     "duration": 2.017853,
     "end_time": "2022-03-20T06:20:47.308335",
     "exception": false,
     "start_time": "2022-03-20T06:20:45.290482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F \n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c7ad5",
   "metadata": {
    "papermill": {
     "duration": 0.021917,
     "end_time": "2022-03-20T06:20:47.352801",
     "exception": false,
     "start_time": "2022-03-20T06:20:47.330884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d5faae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:47.401134Z",
     "iopub.status.busy": "2022-03-20T06:20:47.400126Z",
     "iopub.status.idle": "2022-03-20T06:20:47.562106Z",
     "shell.execute_reply": "2022-03-20T06:20:47.562494Z",
     "shell.execute_reply.started": "2022-03-19T23:33:24.914185Z"
    },
    "papermill": {
     "duration": 0.187828,
     "end_time": "2022-03-20T06:20:47.562643",
     "exception": false,
     "start_time": "2022-03-20T06:20:47.374815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \n",
       "0                          Paper Bag Victoria Secret    249114794  \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891  \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188  \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615884fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:47.613953Z",
     "iopub.status.busy": "2022-03-20T06:20:47.613260Z",
     "iopub.status.idle": "2022-03-20T06:20:47.626403Z",
     "shell.execute_reply": "2022-03-20T06:20:47.626808Z",
     "shell.execute_reply.started": "2022-03-19T23:33:27.882951Z"
    },
    "papermill": {
     "duration": 0.039287,
     "end_time": "2022-03-20T06:20:47.626943",
     "exception": false,
     "start_time": "2022-03-20T06:20:47.587656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500fdad",
   "metadata": {
    "papermill": {
     "duration": 0.022419,
     "end_time": "2022-03-20T06:20:47.672303",
     "exception": false,
     "start_time": "2022-03-20T06:20:47.649884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Cross Validation Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99bd5a14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:47.720944Z",
     "iopub.status.busy": "2022-03-20T06:20:47.720397Z",
     "iopub.status.idle": "2022-03-20T06:20:47.889047Z",
     "shell.execute_reply": "2022-03-20T06:20:47.889469Z",
     "shell.execute_reply.started": "2022-03-19T23:33:33.889207Z"
    },
    "papermill": {
     "duration": 0.19484,
     "end_time": "2022-03-20T06:20:47.889629",
     "exception": false,
     "start_time": "2022-03-20T06:20:47.694789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_2464356923</td>\n",
       "      <td>0013e7355ffc5ff8fb1ccad3e42d92fe.jpg</td>\n",
       "      <td>bbd097a7870f4a50</td>\n",
       "      <td>CELANA WANITA  (BB 45-84 KG)Harem wanita (bisa...</td>\n",
       "      <td>2660605217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_1802986387</td>\n",
       "      <td>00144a49c56599d45354a1c28104c039.jpg</td>\n",
       "      <td>f815c9bb833ab4c8</td>\n",
       "      <td>Jubah anak size 1-12 thn</td>\n",
       "      <td>1835033137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_1806152124</td>\n",
       "      <td>0014f61389cbaa687a58e38a97b6383d.jpg</td>\n",
       "      <td>eea7e1c0c04da33d</td>\n",
       "      <td>KULOT PLISKET SALUR /CANDY PLISKET /WISH KULOT...</td>\n",
       "      <td>1565741687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_86570404</td>\n",
       "      <td>0019a3c6755a194cb2e2c12bfc63972e.jpg</td>\n",
       "      <td>ea9af4f483249972</td>\n",
       "      <td>[LOGU] Tempelan kulkas magnet angka, tempelan ...</td>\n",
       "      <td>2359912463</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_831680791</td>\n",
       "      <td>001be52b2beec40ddc1d2d7fc7a68f08.jpg</td>\n",
       "      <td>e1ce953d1a70618f</td>\n",
       "      <td>BIG SALE SEPATU PANTOFEL KULIT KEREN KERJA KAN...</td>\n",
       "      <td>2630990665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "5  train_2464356923  0013e7355ffc5ff8fb1ccad3e42d92fe.jpg  bbd097a7870f4a50   \n",
       "6  train_1802986387  00144a49c56599d45354a1c28104c039.jpg  f815c9bb833ab4c8   \n",
       "7  train_1806152124  0014f61389cbaa687a58e38a97b6383d.jpg  eea7e1c0c04da33d   \n",
       "8    train_86570404  0019a3c6755a194cb2e2c12bfc63972e.jpg  ea9af4f483249972   \n",
       "9   train_831680791  001be52b2beec40ddc1d2d7fc7a68f08.jpg  e1ce953d1a70618f   \n",
       "\n",
       "                                               title  label_group  fold  \n",
       "0                          Paper Bag Victoria Secret    249114794     0  \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045     2  \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891     0  \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188     1  \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069     3  \n",
       "5  CELANA WANITA  (BB 45-84 KG)Harem wanita (bisa...   2660605217     0  \n",
       "6                           Jubah anak size 1-12 thn   1835033137     0  \n",
       "7  KULOT PLISKET SALUR /CANDY PLISKET /WISH KULOT...   1565741687     0  \n",
       "8  [LOGU] Tempelan kulkas magnet angka, tempelan ...   2359912463     2  \n",
       "9  BIG SALE SEPATU PANTOFEL KULIT KEREN KERJA KAN...   2630990665     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Somebody uploaded this folds in notebook, I am not able to recall his or her name, this saved time for me\n",
    "data = pd.read_csv('../input/crossvalidationfolds/folds.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8977973b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:47.944199Z",
     "iopub.status.busy": "2022-03-20T06:20:47.943404Z",
     "iopub.status.idle": "2022-03-20T06:20:47.950750Z",
     "shell.execute_reply": "2022-03-20T06:20:47.950168Z",
     "shell.execute_reply.started": "2022-03-19T23:33:38.198401Z"
    },
    "papermill": {
     "duration": 0.037522,
     "end_time": "2022-03-20T06:20:47.950898",
     "exception": false,
     "start_time": "2022-03-20T06:20:47.913376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11014\n"
     ]
    }
   ],
   "source": [
    "# number of unique classes in dataset\n",
    "print(len(np.unique(data['label_group'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb65135",
   "metadata": {
    "papermill": {
     "duration": 0.023716,
     "end_time": "2022-03-20T06:20:47.999136",
     "exception": false,
     "start_time": "2022-03-20T06:20:47.975420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c64ae0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.093764Z",
     "iopub.status.busy": "2022-03-20T06:20:48.093194Z",
     "iopub.status.idle": "2022-03-20T06:20:48.096926Z",
     "shell.execute_reply": "2022-03-20T06:20:48.096486Z",
     "shell.execute_reply.started": "2022-03-20T04:34:48.857943Z"
    },
    "papermill": {
     "duration": 0.074404,
     "end_time": "2022-03-20T06:20:48.097033",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.022629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../input/shopee-product-matching/train_images'\n",
    "TEST_DIR = '../input/shopee-product-matching/test_images'\n",
    "TRAIN_CSV = '../input/crossvalidationfolds/folds.csv'\n",
    "MODEL_PATH = './'\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    seed = 123 \n",
    "    img_size = 512\n",
    "    classes = 11014\n",
    "    fc_dim = 512\n",
    "    epochs = 15\n",
    "    batch_size = 32\n",
    "    num_workers = 3\n",
    "    model_name = 'tf_efficientnet_b4'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    scheduler_params = {\n",
    "        \"lr_start\": 1e-3,\n",
    "        \"lr_max\": 1e-5 * batch_size,\n",
    "        \"lr_min\": 1e-6,\n",
    "        \"lr_ramp_ep\": 5,\n",
    "        \"lr_sus_ep\": 0,\n",
    "        \"lr_decay\": 0.8,\n",
    "    }\n",
    "    isTraining=False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1efc60b",
   "metadata": {
    "papermill": {
     "duration": 0.023346,
     "end_time": "2022-03-20T06:20:48.143921",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.120575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Custom DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b56cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.199791Z",
     "iopub.status.busy": "2022-03-20T06:20:48.198239Z",
     "iopub.status.idle": "2022-03-20T06:20:48.200435Z",
     "shell.execute_reply": "2022-03-20T06:20:48.200845Z",
     "shell.execute_reply.started": "2022-03-19T23:33:43.904804Z"
    },
    "papermill": {
     "duration": 0.033257,
     "end_time": "2022-03-20T06:20:48.200964",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.167707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df,root_dir, isTraining=False, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get row at index idx\n",
    "#         print(\"idx\",idx)\n",
    "        \n",
    "        row = self.df.iloc[idx]\n",
    "#         print(row)\n",
    "        label = row.label_group\n",
    "        image_path = os.path.join(self.root_dir, row.image)\n",
    "        \n",
    "        # read image convert to RGB and apply augmentation\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            aug = self.transform(image=image)\n",
    "            image = aug['image']\n",
    "        \n",
    "        return image, torch.tensor(label).long()\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2343db",
   "metadata": {
    "papermill": {
     "duration": 0.023248,
     "end_time": "2022-03-20T06:20:48.247592",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.224344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create data Augmentation For training and validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed825705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.301936Z",
     "iopub.status.busy": "2022-03-20T06:20:48.301273Z",
     "iopub.status.idle": "2022-03-20T06:20:48.303937Z",
     "shell.execute_reply": "2022-03-20T06:20:48.303539Z",
     "shell.execute_reply.started": "2022-03-19T23:33:48.076854Z"
    },
    "papermill": {
     "duration": 0.033021,
     "end_time": "2022-03-20T06:20:48.304039",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.271018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def getAugmentation(IMG_SIZE, isTraining=False):\n",
    "    \n",
    "    if isTraining:\n",
    "        return albumentations.Compose([\n",
    "            albumentations.Resize(IMG_SIZE, IMG_SIZE, always_apply=True),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.Rotate(limit=120, p=0.75),\n",
    "            albumentations.RandomBrightness(limit=(0.09, 0.6), p=0.5),\n",
    "            albumentations.Normalize(\n",
    "                mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ])\n",
    "    else:\n",
    "        return albumentations.Compose([\n",
    "            albumentations.Resize(IMG_SIZE, IMG_SIZE, always_apply=True),\n",
    "            albumentations.Normalize(\n",
    "                mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82f4dc",
   "metadata": {
    "papermill": {
     "duration": 0.023651,
     "end_time": "2022-03-20T06:20:48.352232",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.328581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77500147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.411845Z",
     "iopub.status.busy": "2022-03-20T06:20:48.410301Z",
     "iopub.status.idle": "2022-03-20T06:20:48.412436Z",
     "shell.execute_reply": "2022-03-20T06:20:48.412832Z",
     "shell.execute_reply.started": "2022-03-19T23:33:51.119303Z"
    },
    "papermill": {
     "duration": 0.037055,
     "end_time": "2022-03-20T06:20:48.412946",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.375891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeLabelGroupClassfier(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                     model_name='tf_efficientnet_b0',\n",
    "                     loss_fn='softmax',\n",
    "                     classes = CFG.classes,\n",
    "                     fc_dim = CFG.fc_dim,\n",
    "                     pretrained=True,\n",
    "                     use_fc=True,\n",
    "                     isTraining=False\n",
    "                ):\n",
    "        \n",
    "        \n",
    "        super(ShopeeLabelGroupClassfier,self).__init__()\n",
    "        \n",
    "        # create bottlenack backbone network from pretrained model \n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        in_features = self.backbone.classifier.in_features\n",
    "        # we will put FC layers over backbone to classfy images based on label groups\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.use_fc = use_fc\n",
    "        self.loss_fn =loss_fn\n",
    "        \n",
    "        # build top fc layers\n",
    "        if self.use_fc:\n",
    "            self.dropout = nn.Dropout(0.2)\n",
    "            self.fc = nn.Linear(in_features,fc_dim )\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            in_features = fc_dim\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "        if self.loss_fn=='softmax':\n",
    "            self.final = nn.Linear(in_features, CFG.classes)\n",
    "    \n",
    "    def forward(self, image, label):\n",
    "        features = self.get_features(image)\n",
    "        \n",
    "        if self.loss_fn=='softmax':\n",
    "            logits = self.final(features)\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def get_features(self,inp):\n",
    "        batch_dim = inp.shape[0]\n",
    "        inp = self.backbone(inp)\n",
    "        inp = self.pooling(inp).view(batch_dim, -1)\n",
    "        if self.use_fc:\n",
    "            inp = self.dropout(inp)\n",
    "            inp = self.fc(inp)\n",
    "            inp = self.bn(inp)\n",
    "        \n",
    "        return inp\n",
    "    \n",
    "    \n",
    "# shoppe_label_classfier = ShopeeLabelGroupClassfier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ac4c08",
   "metadata": {
    "papermill": {
     "duration": 0.023294,
     "end_time": "2022-03-20T06:20:48.459841",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.436547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build training  and validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "658e9fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.518283Z",
     "iopub.status.busy": "2022-03-20T06:20:48.517544Z",
     "iopub.status.idle": "2022-03-20T06:20:48.519463Z",
     "shell.execute_reply": "2022-03-20T06:20:48.519862Z",
     "shell.execute_reply.started": "2022-03-19T23:33:54.823644Z"
    },
    "papermill": {
     "duration": 0.036708,
     "end_time": "2022-03-20T06:20:48.519978",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.483270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_one_epoch(epoch_num,model, dataloader,optimizer, scheduler, device, loss_criteria):\n",
    "    avgloss = 0.0\n",
    "    # put model in traning model\n",
    "    model.train()\n",
    "    tq = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    \n",
    "    for idx, data in tq:\n",
    "        batch_size = data[0].shape[0]\n",
    "        images = data[0]\n",
    "        targets = data[1]\n",
    "        # zero out gradient\n",
    "        optimizer.zero_grad()\n",
    "        # put input and target to device\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # pass input to the model\n",
    "        output = model(images,targets)\n",
    "        # get loss\n",
    "        loss = loss_criteria(output,targets)\n",
    "        # backpropogation \n",
    "        loss.backward()\n",
    "        # update learning rate step\n",
    "        optimizer.step() \n",
    "        # avg loss\n",
    "        avgloss += loss.item() \n",
    "\n",
    "        tq.set_postfix({'loss' : '%.6f' %float(avgloss/(idx+1)), 'LR' : optimizer.param_groups[0]['lr']})\n",
    "        \n",
    "    # lr scheduler step after each epoch\n",
    "    scheduler.step()\n",
    "    return avgloss / len(dataloader)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def validation_one_epoch(model, dataloader, epoch, device, loss_criteria):\n",
    "    avgloss = 0.0\n",
    "    # put model in traning model\n",
    "    model.eval()\n",
    "    tq = tqdm(enumerate(dataloader), desc = \"Training Epoch { }\" + str(epoch+1))\n",
    "    \n",
    "    #     tq = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    with torch.no_grad():\n",
    "        for idx, data in tq:\n",
    "            batch_size = data[0].shape[0]\n",
    "            images = data[0]\n",
    "            targets = data[1]\n",
    "\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            output = model(images,targets)\n",
    "            loss = loss_criteria(output,targets)\n",
    "\n",
    "            avgloss += loss.item() \n",
    "\n",
    "            tq.set_postfix({'validation loss' : '%.6f' %float(avgloss/(idx+1))})\n",
    "\n",
    "    return avgloss / len(dataloader)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1e657e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.574043Z",
     "iopub.status.busy": "2022-03-20T06:20:48.572677Z",
     "iopub.status.idle": "2022-03-20T06:20:48.574822Z",
     "shell.execute_reply": "2022-03-20T06:20:48.575209Z",
     "shell.execute_reply.started": "2022-03-19T23:34:56.778989Z"
    },
    "papermill": {
     "duration": 0.032102,
     "end_time": "2022-03-20T06:20:48.575345",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.543243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def get_class_weights(data):\n",
    "    \n",
    "#     data=train_data\n",
    "\n",
    "\n",
    "    weight_dict=dict()\n",
    "    for t in data.values:\n",
    "        weight_dict[t[4]]=0\n",
    "    print(len(weight_dict))\n",
    "    for t in data.values:\n",
    "        weight_dict[t[4]]+=1\n",
    "\n",
    "    class_sample_count= np.array([weight_dict[t[4]] for t in data.values])\n",
    "    weight = 1. / class_sample_count\n",
    "    weight=torch.from_numpy(weight)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38afd72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.626755Z",
     "iopub.status.busy": "2022-03-20T06:20:48.625993Z",
     "iopub.status.idle": "2022-03-20T06:20:48.628240Z",
     "shell.execute_reply": "2022-03-20T06:20:48.627837Z"
    },
    "papermill": {
     "duration": 0.028921,
     "end_time": "2022-03-20T06:20:48.628364",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.599443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../input/crossvalidationfolds/folds.csv')\n",
    "    \n",
    "# # label encoding\n",
    "# labelencoder= LabelEncoder()\n",
    "# data['label_group_original']=data['label_group']\n",
    "# data['label_group'] = labelencoder.fit_transform(data['label_group'])\n",
    "# #data['weights'] = data['label_group'].map(1/data['label_group'].value_counts())\n",
    "# # create training_data and validation data initially not using k fold\n",
    "# train_data = data[data['fold']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26cae439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.680213Z",
     "iopub.status.busy": "2022-03-20T06:20:48.678736Z",
     "iopub.status.idle": "2022-03-20T06:20:48.680829Z",
     "shell.execute_reply": "2022-03-20T06:20:48.681214Z"
    },
    "papermill": {
     "duration": 0.029662,
     "end_time": "2022-03-20T06:20:48.681350",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.651688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# def make_weights_for_balanced_classes(images, nclasses):\n",
    "#     '''\n",
    "#         Make a vector of weights for each image in the dataset, based\n",
    "#         on class frequency. The returned vector of weights can be used\n",
    "#         to create a WeightedRandomSampler for a DataLoader to have\n",
    "#         class balancing when sampling for a training batch.\n",
    "#             images - torchvisionDataset.imgs\n",
    "#             nclasses - len(torchvisionDataset.classes)\n",
    "#         https://discuss.pytorch.org/t/balanced-sampling-between-classes-with-torchvision-dataloader/2703/3\n",
    "#     '''\n",
    "#     count = [0] * nclasses\n",
    "#     for item in images:\n",
    "#         count[item[1]] += 1  # item is (img-data, label-id)\n",
    "#     weight_per_class = [0.] * nclasses\n",
    "#     N = float(sum(count))  # total number of images\n",
    "#     for i in range(nclasses):\n",
    "#         weight_per_class[i] = N / float(count[i])\n",
    "#     weight = [0] * len(images)\n",
    "#     for idx, val in enumerate(images):\n",
    "#         weight[idx] = weight_per_class[val[1]]\n",
    "\n",
    "#     return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88600973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.744084Z",
     "iopub.status.busy": "2022-03-20T06:20:48.736127Z",
     "iopub.status.idle": "2022-03-20T06:20:48.745906Z",
     "shell.execute_reply": "2022-03-20T06:20:48.746294Z",
     "shell.execute_reply.started": "2022-03-19T23:34:40.910178Z"
    },
    "papermill": {
     "duration": 0.041238,
     "end_time": "2022-03-20T06:20:48.746460",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.705222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    data = pd.read_csv('../input/crossvalidationfolds/folds.csv')\n",
    "    \n",
    "    # label encoding\n",
    "    labelencoder= LabelEncoder()\n",
    "    data['label_group_original']=data['label_group']\n",
    "    data['label_group'] = labelencoder.fit_transform(data['label_group'])\n",
    "    #data['weights'] = data['label_group'].map(1/data['label_group'].value_counts())\n",
    "    # create training_data and validation data initially not using k fold\n",
    "    train_data = data[data['fold']!=0]\n",
    "    # get weights for  classes\n",
    "    samples_weight=get_class_weights(train_data)\n",
    "    \n",
    "    print(\"samples_weight\", len(samples_weight))\n",
    "    validation_data = data[data['fold']==0]\n",
    "    \n",
    "    # training augmentation\n",
    "    train_aug = getAugmentation(CFG.img_size,isTraining=True )\n",
    "    validation_aug = getAugmentation(CFG.img_size, isTraining=False)\n",
    "    # create custom train and validation dataset\n",
    "    \n",
    "    trainset = ShopeeDataset(train_data, TRAIN_DIR, isTraining=True, transform = train_aug)\n",
    "    validset = ShopeeDataset(validation_data, TRAIN_DIR, isTraining=False, transform = validation_aug)\n",
    "    print(len(data), len(samples_weight))\n",
    "    print(len(trainset))\n",
    "    # create data sampler\n",
    "                  \n",
    "    sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, num_samples=len(samples_weight))   \n",
    "    \n",
    "    # create custom training and validation data loader num_workers=CFG.num_workers,\n",
    "    train_dataloader = DataLoader(trainset, batch_size=CFG.batch_size,\n",
    "                          drop_last=True,pin_memory=True, sampler=sampler)\n",
    "    \n",
    "    validation_dataloader = DataLoader(validset, batch_size=CFG.batch_size,\n",
    "                         drop_last=True,pin_memory=True)\n",
    "    \n",
    "    \n",
    "    # define loss function\n",
    "    loss_criteria = nn.CrossEntropyLoss()\n",
    "    loss_criteria.to(CFG.device)\n",
    "    # define model\n",
    "    \n",
    "    model = ShopeeLabelGroupClassfier()\n",
    "    model.to(CFG.device)\n",
    "    \n",
    "    # define optimzer\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr= CFG.scheduler_params['lr_start'])\n",
    "    \n",
    "    # learning rate scheudler\n",
    "    scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=7, T_mult=1, eta_min=1e-6, last_epoch=-1)\n",
    "    \n",
    "    history = {'train_loss':[],'validation_loss':[]}\n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        # get current epoch training loss\n",
    "        avg_train_loss = training_one_epoch(epoch_num = epoch,\n",
    "                                           model = model,\n",
    "                                           dataloader = train_dataloader,\n",
    "                                           optimizer = optimizer,\n",
    "                                           scheduler = scheduler,\n",
    "                                           device = CFG.device, \n",
    "                                           loss_criteria = loss_criteria)\n",
    "        \n",
    "        # get current epoch validation loss\n",
    "        avg_validation_loss = validation_one_epoch(model = model,\n",
    "                                           dataloader = validation_dataloader,\n",
    "                                           epoch = epoch,\n",
    "                                           device = CFG.device,\n",
    "                                           loss_criteria = loss_criteria)\n",
    "        \n",
    "        \n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['validation_loss'].append(avg_validation_loss)\n",
    "        \n",
    "        # save model\n",
    "        torch.save(model.state_dict(), MODEL_PATH + str(date.today()) +'_softmax_512x512_{}.pt'.format(CFG.model_name))\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "#             'scheduler': lr_scheduler.state_dict()\n",
    "            },\n",
    "            MODEL_PATH + str(date.today()) +'_softmax_512x512_{}_checkpoints.pt'.format(CFG.model_name)\n",
    "        )\n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "386ea3e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.797709Z",
     "iopub.status.busy": "2022-03-20T06:20:48.796991Z",
     "iopub.status.idle": "2022-03-20T06:20:48.799260Z",
     "shell.execute_reply": "2022-03-20T06:20:48.798857Z"
    },
    "papermill": {
     "duration": 0.029315,
     "end_time": "2022-03-20T06:20:48.799384",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.770069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weight = 1. / class_sample_count\n",
    "# samples_weight = np.array([weight[t] for t in y_train])\n",
    "# samples_weight = torch.from_numpy(samples_weight)\n",
    "# Now, that we have the weights for each of the classes, we can define a sampler.\n",
    "\n",
    "# sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))\n",
    "# Finally, we can use the sampler, while defining the Dataloader.\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=4, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a769ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.852613Z",
     "iopub.status.busy": "2022-03-20T06:20:48.851985Z",
     "iopub.status.idle": "2022-03-20T06:20:48.854597Z",
     "shell.execute_reply": "2022-03-20T06:20:48.854995Z"
    },
    "papermill": {
     "duration": 0.031847,
     "end_time": "2022-03-20T06:20:48.855107",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.823260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "599dce5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.909457Z",
     "iopub.status.busy": "2022-03-20T06:20:48.908732Z",
     "iopub.status.idle": "2022-03-20T06:20:48.911040Z",
     "shell.execute_reply": "2022-03-20T06:20:48.910629Z",
     "shell.execute_reply.started": "2022-03-20T04:35:00.417611Z"
    },
    "papermill": {
     "duration": 0.030723,
     "end_time": "2022-03-20T06:20:48.911136",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.880413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history=None\n",
    "if CFG.isTraining:\n",
    "    model, history = run_training()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "809a8e8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:48.962501Z",
     "iopub.status.busy": "2022-03-20T06:20:48.961729Z",
     "iopub.status.idle": "2022-03-20T06:20:48.966765Z",
     "shell.execute_reply": "2022-03-20T06:20:48.966338Z",
     "shell.execute_reply.started": "2022-03-20T04:34:12.284132Z"
    },
    "papermill": {
     "duration": 0.031505,
     "end_time": "2022-03-20T06:20:48.966862",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.935357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.isTraining:\n",
    "    epoch_lst = [ i+1 for i in range(15)]\n",
    "    plt.plot(epoch_lst,history['train_loss'])\n",
    "\n",
    "    plt.xlabel(\"Epoch number\")\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title('Training Loss SoftMax Loss Function')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a21a535c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-20T06:20:49.021887Z",
     "iopub.status.busy": "2022-03-20T06:20:49.021242Z",
     "iopub.status.idle": "2022-03-20T06:20:49.023819Z",
     "shell.execute_reply": "2022-03-20T06:20:49.024180Z",
     "shell.execute_reply.started": "2022-03-20T06:19:32.547408Z"
    },
    "papermill": {
     "duration": 0.033169,
     "end_time": "2022-03-20T06:20:49.024328",
     "exception": false,
     "start_time": "2022-03-20T06:20:48.991159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.isTraining:\n",
    "    plt.plot(epoch_lst,history['validation_loss'])\n",
    "    plt.xlabel(\"Epoch number\")\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.title('Validation Loss SoftMax Loss Function')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.024384,
   "end_time": "2022-03-20T06:20:50.258440",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-20T06:20:33.234056",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
