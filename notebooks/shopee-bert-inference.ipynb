{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ed5888",
   "metadata": {
    "papermill": {
     "duration": 0.007693,
     "end_time": "2022-09-24T00:29:16.921187",
     "exception": false,
     "start_time": "2022-09-24T00:29:16.913494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Shopee-Product-Matching\n",
    "![Shopee](https://cdn.lynda.com/course/563030/563030-636270778700233910-16x9.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe48f2",
   "metadata": {
    "papermill": {
     "duration": 0.004761,
     "end_time": "2022-09-24T00:29:16.931478",
     "exception": false,
     "start_time": "2022-09-24T00:29:16.926717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Similar to images, we can use pretrained neural network-based model in order to extract Text embeddings for sentences. One of the popular is for sure **BERT**.\n",
    "\n",
    "* Some High Level Explanation For **ArcFace Loss** borrowed from [eneszvo's notebook](https://www.kaggle.com/code/eneszvo/shopee-summary-efficientnet-arcface-bert#Pretrained-embedding)\n",
    "\n",
    "\n",
    "# ArcFace embedding\n",
    "\n",
    "Modification that forces similar class embeddings to be closer and dissimilar more distant. The simple example with MNIST https://www.kaggle.com/slawekbiel/arcface-explained/.\n",
    "\n",
    "Basically, it modifies the softmax loss function in order to achieve better separation for different classes in the embedding space. To understand the formula lets first recall cross-entropy loss and softmax definition.\n",
    "\n",
    "**Cross-entropy loss** - measures the performance of a classification model whose output is a probability value between 0 and 1. Usually used for multi-class classification. \n",
    "$$CE = -\\sum_{i=1}^{C} t_{i}\\log(a_{i})$$\n",
    "where $C$ is the number of classes, $t$ is mostly a one-hot vector (or binary vector for multi-label classification) representing labels, and $a$ activation function (usually the output function in the NN).\n",
    "\n",
    "**Softmax function** - the activation function in the output layer of neural network models that predict a multinomial probability distribution.\n",
    "$$ softmax(x_{i}) = \\frac{e^{x_{i}}}{\\sum_{j=1}^{n} e^{x_{j}}}$$\n",
    "where $x$ is $n$-dimensional vector.\n",
    "\n",
    "**Softmax loss** - cross-entropy loss applied on softmax activation function,\n",
    "$$CE = -\\sum_{i=1}^{C} t_{i}\\log(a_{i}) = -\\sum_{i=1}^{C} t_{i}\\log(\\frac{e^{x_{i}}}{\\sum_{j=1}^{n} e^{x_{j}}}).$$\n",
    "\n",
    "If $t=(t_{1}, t_{2},..., t_{C})$ is one-hot vector where $t_{i}=1$, then softmax loss becomes\n",
    "$$CE = -\\log(\\frac{e^{x_{i}}}{\\sum_{j=1}^{n} e^{x_{j}}}).$$\n",
    "\n",
    "**Softmax cost** function is the average of the loss functions over the training set (or batch), \n",
    "$$CE = -\\frac{1}{N}\\sum_{i=1}^{N}\\log(\\frac{e^{x_{i}}}{\\sum_{j=1}^{n} e^{x_{j}}}).$$\n",
    "Based on the figure below,\n",
    "\n",
    "**softmax cost** can be written as\n",
    "$$CE = -\\frac{1}{N}\\sum_{i}^{N}\\log(\\frac{e^{W_{y_{i}}^{T}x_{i} + b_{y_{i}}}}{\\sum_{j=1}^{n} e^{W_{j}^{T}x_{i} + b_{j}}}).$$\n",
    "where $x_{i}$ denotes embedding of the $i$-th sample, belonging to the $y_{i}$-th class (from the image above, $y_{i}=2$). $W_{j}$ denotes the $j$-th column of the weight matrix $W$.\n",
    "\n",
    "Lets fix $b=\\mathbf{0}$, normalize all weight columns $\\Vert W_{j}\\Vert=1$ and normalize embedding vector $\\Vert x\\Vert=1$. After normalization, embedding will be distributed on a unit hypersphere. Now we have that \n",
    "$$W_{j}^{T}x + b_{j}=\\frac{W_{j}^{T}x}{\\Vert W_{j}\\Vert\\Vert x\\Vert} = \\cos(\\langle W_{j}^{T}, x\\rangle)=\\cos(\\theta_{j}).$$\n",
    "\n",
    "Further, we can easily get $\\theta$ angle applying $\\arccos$ to both sides and after increase $\\theta$ by penalty $m$. From the ArcFace paper https://arxiv.org/pdf/1801.07698.pdf, autors explained it as:  \n",
    "> We add an additive angular margin penalty $m$ between $x_{i}$ and $W_{y_{i}}$ to simultaneously enhance the intra-class compactness and inter-class discrepancy.\n",
    "\n",
    "After all, the softmax cost becomes \n",
    "$$CE = -\\frac{1}{N}\\sum_{i}^{N}\\log(\\frac{e^{s \\cos(\\theta_{y_{i}}+m)}}{e^{s \\cos(\\theta_{y_{i}}+m)} + \\sum_{j=1, j\\neq y_{i}}^{n} e^{s \\cos(\\theta_{j})}})$$\n",
    "where $s$ is a scaler that defines the radius of hypersphere where embeddings are distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1cb333",
   "metadata": {
    "papermill": {
     "duration": 0.004727,
     "end_time": "2022-09-24T00:29:16.941199",
     "exception": false,
     "start_time": "2022-09-24T00:29:16.936472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* I already trained Image Model using ArcFace Module, Please check this Training notebook [ArcFace Training Image Model](https://github.com/cr21/Shopee-Product-Matching/blob/main/notebooks/ArcfaceLoss%5Btraining%5D.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d12be5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:16.953389Z",
     "iopub.status.busy": "2022-09-24T00:29:16.952578Z",
     "iopub.status.idle": "2022-09-24T00:29:16.970156Z",
     "shell.execute_reply": "2022-09-24T00:29:16.969326Z"
    },
    "papermill": {
     "duration": 0.026055,
     "end_time": "2022-09-24T00:29:16.972181",
     "exception": false,
     "start_time": "2022-09-24T00:29:16.946126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061fe57",
   "metadata": {
    "papermill": {
     "duration": 0.004742,
     "end_time": "2022-09-24T00:29:16.981832",
     "exception": false,
     "start_time": "2022-09-24T00:29:16.977090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1cdbc68",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:16.993486Z",
     "iopub.status.busy": "2022-09-24T00:29:16.992588Z",
     "iopub.status.idle": "2022-09-24T00:29:21.128740Z",
     "shell.execute_reply": "2022-09-24T00:29:21.127636Z"
    },
    "papermill": {
     "duration": 4.144482,
     "end_time": "2022-09-24T00:29:21.131381",
     "exception": false,
     "start_time": "2022-09-24T00:29:16.986899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timmmaster')\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434739e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:21.144450Z",
     "iopub.status.busy": "2022-09-24T00:29:21.143406Z",
     "iopub.status.idle": "2022-09-24T00:29:26.235764Z",
     "shell.execute_reply": "2022-09-24T00:29:26.234824Z"
    },
    "papermill": {
     "duration": 5.101293,
     "end_time": "2022-09-24T00:29:26.238259",
     "exception": false,
     "start_time": "2022-09-24T00:29:21.136966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F \n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from datetime import date\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from collections  import Counter\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch.nn.functional as F \n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml import PCA\n",
    "from cuml.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a2a23",
   "metadata": {
    "papermill": {
     "duration": 0.004851,
     "end_time": "2022-09-24T00:29:26.248558",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.243707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a366d177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.261498Z",
     "iopub.status.busy": "2022-09-24T00:29:26.259754Z",
     "iopub.status.idle": "2022-09-24T00:29:26.267383Z",
     "shell.execute_reply": "2022-09-24T00:29:26.266498Z"
    },
    "papermill": {
     "duration": 0.015887,
     "end_time": "2022-09-24T00:29:26.269549",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.253662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../input/shopee-product-matching/train_images'\n",
    "TEST_DIR = '../input/shopee-product-matching/test_images'\n",
    "TRAIN_CSV = '../input/shopee-product-matching/train.csv'\n",
    "TEST_CSV='../input/shopee-product-matching/test.csv'\n",
    "MODEL_PATH = './'\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    seed = 18900 \n",
    "    num_workers = 3\n",
    "    bert_model_name = '../input/bertmodel/paraphrase-xlm-r-multilingual-v1'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    \n",
    "    ## ARCFACE\n",
    "\n",
    "    scale = 30\n",
    "    margin = 0.5\n",
    "    fc_dim = 768\n",
    "    classes = 11014\n",
    "    \n",
    "    batch_size = 16\n",
    "    use_fc=True\n",
    "    max_length=128\n",
    "    ### NearestNeighbors\n",
    "    bert_knn = 42\n",
    "    chunk = 32\n",
    "    max_preds = 42\n",
    "    nearlest_one = True # True is better\n",
    "    bert_knn_threshold = 0.84  # Cosine distance threshold\n",
    "    \n",
    "    # MAke it TRue For Testing or submission\n",
    "    COMPUTE_CV=True\n",
    "    use_auto_mix_precision=False\n",
    "    bert_model_path =  \"../input/bert-trained-22/paraphrase-xlm-r-multilingual-v1_epoch7-bs16x1.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8397f3dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.281984Z",
     "iopub.status.busy": "2022-09-24T00:29:26.280486Z",
     "iopub.status.idle": "2022-09-24T00:29:26.288807Z",
     "shell.execute_reply": "2022-09-24T00:29:26.287973Z"
    },
    "papermill": {
     "duration": 0.016437,
     "end_time": "2022-09-24T00:29:26.290928",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.274491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True # set True to be faster\n",
    "\n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56422e",
   "metadata": {
    "papermill": {
     "duration": 0.004788,
     "end_time": "2022-09-24T00:29:26.300786",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.295998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Solution Approach\n",
    "\n",
    "* In this competition it is given that,if two or more images have **same label group** then they are **similar products.** \n",
    "* Basically we can use this information to transfer the business problem into **multi class classification** problem.\n",
    "* From Image EDA, I found out that we have **11014** different classes, and dataset is **not balanced dataset**\n",
    "* If you see below plot, we can clearly see that there are **hardly 1000 data points having more than 10 products per label.*\n",
    "* In this notebook I used **Weighted Sampler technique used in pytorch for handling imbalanced classification problem**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9069ce69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.311694Z",
     "iopub.status.busy": "2022-09-24T00:29:26.311433Z",
     "iopub.status.idle": "2022-09-24T00:29:26.316423Z",
     "shell.execute_reply": "2022-09-24T00:29:26.315532Z"
    },
    "papermill": {
     "duration": 0.012757,
     "end_time": "2022-09-24T00:29:26.318505",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.305748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    if CFG.COMPUTE_CV:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "        print(\"Total Number of Train DAta\", df.shape[0])\n",
    "    else:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "        print(\"Total Number of Test Data\", df.shape[0])\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d3e9b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.330355Z",
     "iopub.status.busy": "2022-09-24T00:29:26.330097Z",
     "iopub.status.idle": "2022-09-24T00:29:26.335948Z",
     "shell.execute_reply": "2022-09-24T00:29:26.335065Z"
    },
    "papermill": {
     "duration": 0.013415,
     "end_time": "2022-09-24T00:29:26.337836",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.324421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e08da2",
   "metadata": {
    "papermill": {
     "duration": 0.004719,
     "end_time": "2022-09-24T00:29:26.347380",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.342661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b876584c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.358637Z",
     "iopub.status.busy": "2022-09-24T00:29:26.358386Z",
     "iopub.status.idle": "2022-09-24T00:29:26.368803Z",
     "shell.execute_reply": "2022-09-24T00:29:26.367913Z"
    },
    "papermill": {
     "duration": 0.018725,
     "end_time": "2022-09-24T00:29:26.371026",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.352301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcFaceModule(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30, margin=0.5, easy_margin=False, ls_eps=0.0 ):\n",
    "        super(ArcFaceModule, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        self.easy_margin=easy_margin\n",
    "        self.ls_eps=ls_eps\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, input, label):\n",
    "        \n",
    "        # cosine = X.W = ||X|| .||W|| . cos(theta) \n",
    "        # if X and W are normalize then dot product X, W = will be cos theta\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        # sin(theta)^2 = 1 - cos(theta)^2\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        # phi = cos(theta + margin) = cos theta . cos(margin) -  sine theta .  sin(margin)\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            # torch.tensor(a,dtype=torch.float16)\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "            \n",
    "        \n",
    "        one_hot = torch.zeros(cosine.size(), device=CFG.device)\n",
    "        # one hot encoded\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        #  output = label == True ? phi : cosine  \n",
    "        # Add Margin to true label direction only \n",
    "        # Add normal cosine to other class weight direction\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        # scale the output\n",
    "        output *= self.scale\n",
    "        # return cross entropy loss on scalled output\n",
    "        return output, nn.CrossEntropyLoss()(output,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169eb1a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.382619Z",
     "iopub.status.busy": "2022-09-24T00:29:26.381815Z",
     "iopub.status.idle": "2022-09-24T00:29:26.387399Z",
     "shell.execute_reply": "2022-09-24T00:29:26.386541Z"
    },
    "papermill": {
     "duration": 0.013353,
     "end_time": "2022-09-24T00:29:26.389350",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.375997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    # First element of model_output contains all token embeddings\n",
    "    token_embeddings = model_output[0]  \n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49e2ae89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.400510Z",
     "iopub.status.busy": "2022-09-24T00:29:26.400260Z",
     "iopub.status.idle": "2022-09-24T00:29:26.412699Z",
     "shell.execute_reply": "2022-09-24T00:29:26.411744Z"
    },
    "papermill": {
     "duration": 0.020543,
     "end_time": "2022-09-24T00:29:26.414857",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.394314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "   \n",
    "    \n",
    "    \n",
    "class ShopeeBertEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                     model_name=None,\n",
    "                     loss_fn='ArcFace',\n",
    "                     classes = CFG.classes,\n",
    "                     fc_dim = CFG.fc_dim,\n",
    "                     pretrained=True,\n",
    "                     use_fc=True,\n",
    "                     COMPUTE_CV=CFG.COMPUTE_CV,\n",
    "                     margin = CFG.margin,\n",
    "                    scale = CFG.scale,\n",
    "                ):\n",
    "        \n",
    "        super(ShopeeBertEncoder,self).__init__()\n",
    "        print(\"Building Model Backbone for {}\".format(model_name))\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        # create bottlenack backbone network from pretrained model \n",
    "        self.backbone = AutoModel.from_pretrained(model_name).to(CFG.device)\n",
    "        in_features = 768\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.classifier = nn.Linear(in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self.init_params()\n",
    "        in_features = fc_dim\n",
    "\n",
    "        if loss_fn=='softmax':\n",
    "            self.final = nn.Linear(in_features, CFG.classes)\n",
    "        elif loss_fn =='ArcFace':\n",
    "            self.final = ArcFaceModule( in_features,\n",
    "                                        CFG.classes,\n",
    "                                        scale = scale,\n",
    "                                        margin = margin,\n",
    "                                        easy_margin = False,\n",
    "                                        ls_eps = 0.0)\n",
    "            \n",
    "    def forward(self, texts, labels=torch.tensor([0])):\n",
    "        features = self.get_features(texts)\n",
    "        \n",
    "        if self.training:\n",
    "            logits = self.final(features,  labels.to(CFG.device))\n",
    "            return logits\n",
    "        else:\n",
    "            return features\n",
    "    \n",
    "    def init_params(self):\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "        nn.init.constant_(self.classifier.bias,0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "        \n",
    "        \n",
    "    def get_features(self,texts):\n",
    "        \n",
    "        encoding = self.tokenizer(texts, \n",
    "                                  padding=True,\n",
    "                                  truncation=True,\n",
    "                                  max_length = CFG.max_length,\n",
    "                                  return_tensors='pt').to(CFG.device)\n",
    "        input_ids = encoding['input_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        \n",
    "        embedding = self.backbone(input_ids, attention_mask=attention_mask)\n",
    "        x = mean_pooling(embedding, attention_mask)\n",
    "        \n",
    "        if self.use_fc :\n",
    "            x = self.dropout(x)\n",
    "            x = self.classifier(x)\n",
    "            x = self.bn(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b25b1",
   "metadata": {
    "papermill": {
     "duration": 0.005043,
     "end_time": "2022-09-24T00:29:26.424893",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.419850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03581940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.435716Z",
     "iopub.status.busy": "2022-09-24T00:29:26.435449Z",
     "iopub.status.idle": "2022-09-24T00:29:26.446327Z",
     "shell.execute_reply": "2022-09-24T00:29:26.445517Z"
    },
    "papermill": {
     "duration": 0.018434,
     "end_time": "2022-09-24T00:29:26.448276",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.429842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bert_Embeddings(df, col, model_name,model_path,fc_dim=768, use_fc=True, chunk=8):\n",
    "    \n",
    "    print(\"Getting BERT ArcFace Embeddings\")\n",
    "    # this is costly GPU operation so we need to be very careful\n",
    "    \n",
    "    # built model from trained weights, put model in evalution mode\n",
    "    model = ShopeeBertEncoder(model_name=model_name, fc_dim=fc_dim, use_fc=use_fc)\n",
    "    model.to(CFG.device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=CFG.device))\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    \n",
    "    bert_embeddings = torch.zeros((df.shape[0], fc_dim)).to(CFG.device)\n",
    "    for i in tqdm(list(range(0, df.shape[0], chunk)) + [df.shape[0]-chunk], desc=\"get_bert_embeddings\", ncols=80):\n",
    "        \n",
    "        titles = []\n",
    "        \n",
    "        # get title chunk wise\n",
    "        for title in df[col][i:i+chunk].values:\n",
    "            try:\n",
    "                # preprocess title before passing through tokenization part\n",
    "                title = title.encode('utf-8').decode(\"unicode_escape\")\n",
    "                title = title.encode('ascii', 'ignore').decode(\"unicode_escape\")\n",
    "                \n",
    "            except Exception:\n",
    "                raise Exception(\"Title Processing Error\")\n",
    "                \n",
    "            title = title.lower()\n",
    "            titles.append(title)\n",
    "\n",
    "        # get bert embedding by forward pass chunk by chunk\n",
    "        with torch.no_grad():\n",
    "            if CFG.use_auto_mix_precision:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    model_output = model(titles)\n",
    "            else:\n",
    "                model_output = model(titles)\n",
    "\n",
    "        bert_embeddings[i:i+chunk] = model_output  \n",
    "        \n",
    "    del model, titles, model_output\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return bert_embeddings\n",
    "                    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629bf0d",
   "metadata": {
    "papermill": {
     "duration": 0.004838,
     "end_time": "2022-09-24T00:29:26.458159",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.453321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get Top K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a364afb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.469588Z",
     "iopub.status.busy": "2022-09-24T00:29:26.468914Z",
     "iopub.status.idle": "2022-09-24T00:29:26.476542Z",
     "shell.execute_reply": "2022-09-24T00:29:26.475632Z"
    },
    "papermill": {
     "duration": 0.015321,
     "end_time": "2022-09-24T00:29:26.478454",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.463133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getTOPK(df, embeddings, k=50, threshold=CFG.bert_knn_threshold, metric='cosine'):\n",
    "    preds = []\n",
    "    CHUNK = 128\n",
    "    model = NearestNeighbors(n_neighbors=k,metric=metric)\n",
    "    model.fit(embeddings)\n",
    "    \n",
    "    print('Finding similar Title...')\n",
    "    CTS = len(embeddings)//CHUNK\n",
    "    if len(embeddings)%CHUNK!=0: CTS += 1\n",
    "    for j in range( CTS ):\n",
    "\n",
    "        a = j*CHUNK\n",
    "        b = (j+1)*CHUNK\n",
    "        b = min(b,len(embeddings))\n",
    "        print('chunk',a,'to',b)\n",
    "        distances, indices = model.kneighbors(embeddings[a:b,])\n",
    "\n",
    "        for k in range(b-a):\n",
    "            IDX = np.where(distances[k,]<0.83)[0]\n",
    "            IDS = indices[k,IDX]\n",
    "            o = df.iloc[IDS].posting_id.values\n",
    "            preds.append(o)\n",
    "\n",
    "    del model, distances, indices, embeddings\n",
    "    _ = gc.collect()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1244279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.489735Z",
     "iopub.status.busy": "2022-09-24T00:29:26.488987Z",
     "iopub.status.idle": "2022-09-24T00:29:26.493255Z",
     "shell.execute_reply": "2022-09-24T00:29:26.492310Z"
    },
    "papermill": {
     "duration": 0.011891,
     "end_time": "2022-09-24T00:29:26.495225",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.483334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_neighbors(df, embeddings, k=50,threshold=CFG.bert_knn_threshold, metric='cosine'):\n",
    "#     knn_model = NearestNeighbors(n_neighbors = k,metric=metric)\n",
    "#     knn_model.fit(embeddings)\n",
    "#     distances, indices = knn_model.kneighbors(embeddings)\n",
    "#     predictions = []\n",
    "#     for i in tqdm(range(embeddings.shape[0])):\n",
    "#         idx = np.where(distances[i,] < threshold )[0]\n",
    "        \n",
    "#         ids = indices[i,idx]\n",
    "#         posting_ids = df['posting_id'].iloc[ids].values\n",
    "#         predictions.append(posting_ids)\n",
    "    \n",
    "#     del knn_model, distances, indices\n",
    "#     gc.collect()\n",
    "#     return  predictions\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bd515",
   "metadata": {
    "papermill": {
     "duration": 0.00476,
     "end_time": "2022-09-24T00:29:26.505139",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.500379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f26ca27e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.516674Z",
     "iopub.status.busy": "2022-09-24T00:29:26.516070Z",
     "iopub.status.idle": "2022-09-24T00:29:26.530383Z",
     "shell.execute_reply": "2022-09-24T00:29:26.529443Z"
    },
    "papermill": {
     "duration": 0.022588,
     "end_time": "2022-09-24T00:29:26.532677",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.510089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Train DAta 3\n"
     ]
    }
   ],
   "source": [
    "df =read_dataset()\n",
    "\n",
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row[col] for col in CFG.prediction_cols])\n",
    "    return ' '.join( np.unique(x) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c55ec0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:29:26.543902Z",
     "iopub.status.busy": "2022-09-24T00:29:26.543633Z",
     "iopub.status.idle": "2022-09-24T00:30:03.382668Z",
     "shell.execute_reply": "2022-09-24T00:30:03.381737Z"
    },
    "papermill": {
     "duration": 36.847166,
     "end_time": "2022-09-24T00:30:03.384854",
     "exception": false,
     "start_time": "2022-09-24T00:29:26.537688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERT ArcFace Embeddings\n",
      "Building Model Backbone for ../input/bertmodel/paraphrase-xlm-r-multilingual-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_bert_embeddings: 100%|████████████████████████| 2/2 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings.shape: torch.Size([3, 768])\n",
      "Finding similar Title...\n",
      "chunk 0 to 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>test_2255846744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>test_3588702337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>test_4015706929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id          matches\n",
       "0  test_2255846744  test_2255846744\n",
       "1  test_3588702337  test_3588702337\n",
       "2  test_4015706929  test_4015706929"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "bert_embeddings = get_bert_Embeddings(df=df, col='title', model_name=CFG.bert_model_name, model_path=CFG.bert_model_path,\n",
    "                                      fc_dim=768, use_fc=True, chunk=32)\n",
    "print('bert_embeddings.shape:', bert_embeddings.shape)\n",
    "\n",
    "if len(df)<=3:\n",
    "    best_k = 3\n",
    "else:\n",
    "    best_k=42\n",
    "    \n",
    "predictions = getTOPK(df, bert_embeddings.cpu().detach().numpy(), k=best_k, threshold=0.17, metric='cosine')\n",
    "# predictions = get_neighbors(df, , k=_k,threshold=0.17, metric='cosine')\n",
    "\n",
    "df['predictions']=predictions\n",
    "CFG.prediction_cols =['predictions']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['matches'] = df.apply(combine_predictions, axis=1)\n",
    "\n",
    "df[['posting_id', 'matches']].to_csv('submission.csv', index=False)\n",
    "submission_df = pd.read_csv('submission.csv')\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afd3925c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-24T00:30:03.397819Z",
     "iopub.status.busy": "2022-09-24T00:30:03.397504Z",
     "iopub.status.idle": "2022-09-24T00:30:03.402549Z",
     "shell.execute_reply": "2022-09-24T00:30:03.401580Z"
    },
    "papermill": {
     "duration": 0.013551,
     "end_time": "2022-09-24T00:30:03.404544",
     "exception": false,
     "start_time": "2022-09-24T00:30:03.390993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bert_embeddings = get_bert_Embeddings(df=df, col='title', model_name=CFG.bert_model_name, model_path=CFG.bert_model_path,\n",
    "#                                       fc_dim=768, use_fc=True, chunk=32)\n",
    "# print('bert_embeddings.shape:', bert_embeddings.shape)\n",
    "\n",
    "# if len(df) <= 3:\n",
    "#     _k  = 3\n",
    "# else:\n",
    "#     _k=42\n",
    "# predictions = get_neighbors(df, bert_embeddings.cpu().detach().numpy(), k=_k,threshold=0.17, metric='cosine')\n",
    "\n",
    "# df['predictions']=predictions\n",
    "# # df['predictions'] = df['posting_id']\n",
    "# CFG.prediction_cols =['predictions']\n",
    "\n",
    "# def combine_predictions(row):\n",
    "#     x = np.concatenate([row[col] for col in CFG.prediction_cols])\n",
    "#     return ' '.join( np.unique(x) )\n",
    "\n",
    "# if CFG.COMPUTE_CV:\n",
    "#     test_df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "# else:\n",
    "#     test_df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "# test_df = test_df[max_cnt:]\n",
    "# test_df['predictions'] = test_df['posting_id']\n",
    "# test_df['matches'] = test_df['posting_id']\n",
    "\n",
    "\n",
    "# df['matches'] = df.apply(combine_predictions, axis=1)\n",
    "# # df['matches'] = df['posting_id']\n",
    "# df = pd.concat([df, test_df], ignore_index=True)\n",
    "\n",
    "# df[['posting_id', 'matches']].to_csv('submission.csv', index=False)\n",
    "# submission_df = pd.read_csv('submission.csv')\n",
    "# submission_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 56.14047,
   "end_time": "2022-09-24T00:30:05.434035",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-24T00:29:09.293565",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
