{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/chiragtagadiya/arcface-inference-submission?scriptVersionId=93212122\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timmmaster')\nimport timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Libraries","metadata":{}},{"cell_type":"code","source":"# Preliminaries\nfrom tqdm import tqdm\nimport math\nimport random\nimport os\nimport pandas as pd\nimport numpy as np\n\n# Visuals and CV2\nimport cv2\n\n# albumentations for augs\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n#torch\nimport torch\nimport timm\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset,DataLoader\n\n\nimport gc\nimport matplotlib.pyplot as plt\nimport cudf\nimport cuml\nimport cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml import PCA\nfrom cuml.neighbors import NearestNeighbors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configurations ","metadata":{}},{"cell_type":"code","source":"class CFG:\n    seed = 123\n    classes = 11014 \n    scale = 30 \n    margin = 0.5\n    model_name =  'tf_efficientnet_b4'\n    fc_dim = 512\n    image_size = 512\n    batch_size = 12\n    num_workers = 2\n    device = device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model_path_arcface = '../input/pretrained-b3/Train_F1_score_0.9061769859813084valid_f1_score0.4245035046728972_Epoch_0_lr_start_2.23e-05_lr_max_0.00016_softmax_512x512_tf_efficientnet_b0.pt'\n    model_path_softmax='../input/label-classfier-model/2022-04-15_softmax_512x512_tf_efficientnet_b4.pt'\n    isTraining=False\n    # isTesting change it to true for submission, for training data make it false\n    isTesting = False\n    loss_module = 'arcface' #'cosface' #'adacos'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data","metadata":{}},{"cell_type":"code","source":"def read_dataset():\n    if not CFG.isTesting:\n        # if not in testing phase read train dataset else test dataset\n        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n        # WE have information that label_group is same for similar kind of product\n        # let's use this to get F1 score for our final model\n        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n        df['matches'] = df['label_group'].map(tmp)\n        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n        # get cuda frame for faster GPU computation\n        df_cu = cudf.DataFrame(df)\n    else:\n        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n        df_cu = cudf.DataFrame(df)\n        \n    return df, df_cu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Dataset","metadata":{}},{"cell_type":"code","source":"class ShopeeDataset(Dataset):\n    \n    def __init__(self, df,root_dir, isTraining=False, transform=None):\n        self.df = df\n        self.transform = transform\n        self.root_dir = root_dir\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):       \n        row = self.df.iloc[idx]\n        \n        image_path = os.path.join(self.root_dir, row.image)\n        # read image convert to RGB and apply augmentation\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            aug = self.transform(image=image)\n            image = aug['image']\n        if not CFG.isTesting:\n            label = row.label_group\n        else :\n            # we don't have label for test data so return 1\n            label = 1\n        return image, torch.tensor(label).long()\n            \n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef get_test_transforms():\n\n    return albumentations.Compose(\n        [\n            albumentations.Resize(CFG.image_size,CFG.image_size,always_apply=True),\n            albumentations.Normalize(),\n        ToTensorV2(p=1.0)\n        ]\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image Model : Product Labels Classfier\n\n### Model 1: Product Classfier Softmax Loss","metadata":{}},{"cell_type":"code","source":"class ShopeeLabelGroupClassfier1(nn.Module):\n    \n    def __init__(self,\n                     model_name='tf_efficientnet_b0',\n                     loss_fn='softmax',\n                     classes = CFG.classes,\n                     fc_dim = CFG.fc_dim,\n                     pretrained=False,\n                     use_fc=True,\n                     isTraining=False\n                ):\n        \n        \n        super(ShopeeLabelGroupClassfier1,self).__init__()\n        \n        # create bottlenack backbone network from pretrained model \n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.backbone.classifier.in_features\n        # we will put FC layers over backbone to classfy images based on label groups\n        self.backbone.classifier = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.use_fc = use_fc\n        self.loss_fn =loss_fn\n        self.isTraining = isTraining\n        \n        \n    \n    def forward(self, image, label):\n        features = self.get_features(image)\n        print(features.shape)\n        return features\n    \n    def get_features(self,inp):\n        batch_dim = inp.shape[0]\n        inp = self.backbone(inp)\n        inp = self.pooling(inp).view(batch_dim, -1)\n        return inp\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ShopeeLabelGroupClassfier(nn.Module):\n    \n    def __init__(self,\n                     model_name='tf_efficientnet_b0',\n                     loss_fn='softmax',\n                     classes = CFG.classes,\n                     fc_dim = CFG.fc_dim,\n                     pretrained=False,\n                     use_fc=True,\n                     isTraining=False\n                ):\n        \n        \n        super(ShopeeLabelGroupClassfier,self).__init__()\n        \n        # create bottlenack backbone network from pretrained model \n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.backbone.classifier.in_features\n        # we will put FC layers over backbone to classfy images based on label groups\n        self.backbone.classifier = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.use_fc = use_fc\n        self.loss_fn =loss_fn\n        self.isTraining = isTraining\n        \n        # build top fc layers\n        if self.use_fc:\n            self.dropout = nn.Dropout(0.2)\n            self.fc = nn.Linear(in_features,fc_dim )\n            self.bn = nn.BatchNorm1d(fc_dim)\n            in_features = fc_dim\n        self.loss_fn = loss_fn\n        \n        if self.loss_fn=='softmax':\n            self.final = nn.Linear(in_features, CFG.classes)\n    \n    def forward(self, image, label):\n        features = self.get_features(image)\n        if self.loss_fn=='softmax' and CFG.isTraining:\n            logits = self.final(features)\n            return logits\n        else:\n            return features\n    \n    def get_features(self,inp):\n        batch_dim = inp.shape[0]\n        inp = self.backbone(inp)\n        inp = self.pooling(inp).view(batch_dim, -1)\n        if self.use_fc and self.isTraining:\n            inp = self.dropout(inp)\n            inp = self.fc(inp)\n            inp = self.bn(inp)\n        return inp\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model 2: Product Classfier Arcface Loss","metadata":{}},{"cell_type":"code","source":"class ArcFaceModule(nn.Module):\n    def __init__(self, in_features, out_features, scale, margin, easy_margin=False, ls_eps=0.0 ):\n        super(ArcFaceModule, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scale = scale\n        self.margin = margin\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n        self.easy_margin=easy_margin\n        self.ls_eps=ls_eps\n        self.cos_m = math.cos(margin)\n        self.sin_m = math.sin(margin)\n        self.th = math.cos(math.pi - margin)\n        self.mm = math.sin(math.pi - margin) * margin\n        \n        \n        \n    \n    def forward(self, input, label):\n        \n        # cosine = X.W = ||X|| .||W|| . cos(theta) \n        # if X and W are normalize then dot product X, W = will be cos theta\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n        # phi = cos(theta + margin) = cos theta . cos(margin) -  sine theta .  sin(margin)\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n            \n        one_hot = torch.zeros(cosine.size(), device=CFG.device)\n        # one hot encoded\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n        #  output = label == True ? phi : cosine  \n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        # scale the output\n        output *= self.scale\n        # return cross entropy loss on scalled output\n        return output, nn.CrossEntropyLoss()(output,label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"   \nclass ShopeeEncoderBackBone1(nn.Module):\n    \n    def __init__(self,\n                     model_name='tf_efficientnet_b3',\n                     loss_fn='ArcFace',\n                     classes = CFG.classes,\n                     fc_dim = CFG.fc_dim,\n                     pretrained=False,\n                     use_fc=True,\n                     isTraining=False\n                ):\n        \n        \n        super(ShopeeEncoderBackBone1,self).__init__()\n        \n        # create bottlenack backbone network from pretrained model \n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.backbone.classifier.in_features\n        self.backbone.classifier = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.use_fc = use_fc\n        self.loss_fn =loss_fn\n        self.isTraining =isTraining\n        \n        # build top fc layers (Embedding that we are looking at testing time to represent the entire image)\n        if self.use_fc:\n            self.dropout = nn.Dropout(0.2)\n            self.fc = nn.Linear(in_features,fc_dim )\n            self.bn = nn.BatchNorm1d(fc_dim)\n            self.init_params()\n            in_features = fc_dim\n        self.loss_fn = loss_fn\n        if self.loss_fn=='softmax':\n            self.final = nn.Linear(in_features, CFG.classes)\n        elif self.loss_fn =='ArcFace':\n            self.final = ArcFaceModule( in_features,\n                                        CFG.classes,\n                                        scale = 30,\n                                        margin = 0.5,\n                                        easy_margin = False,\n                                        ls_eps = 0.0)\n        \n        \n        \n            \n    def forward(self, image, label):\n        features = self.get_features(image)\n        return features\n    \n    def init_params(self):\n        nn.init.xavier_normal_(self.fc.weight)\n        nn.init.constant_(self.fc.bias,0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n        \n        \n    def get_features(self,inp):\n        batch_dim = inp.shape[0]\n        inp = self.backbone(inp)\n        inp = self.pooling(inp).view(batch_dim, -1)\n        return inp\n    \n    \n# shoppe_label_classfier = ShopeeLabelGroupClassfier()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"   \nclass ShopeeEncoderBackBone(nn.Module):\n    \n    def __init__(self,\n                     model_name='tf_efficientnet_b3',\n                     loss_fn='ArcFace',\n                     classes = CFG.classes,\n                     fc_dim = CFG.fc_dim,\n                     pretrained=False,\n                     use_fc=True,\n                     isTraining=False\n                ):\n        \n        \n        super(ShopeeEncoderBackBone1,self).__init__()\n        \n        # create bottlenack backbone network from pretrained model \n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.backbone.classifier.in_features\n        self.backbone.classifier = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.use_fc = use_fc\n        self.loss_fn =loss_fn\n        self.isTraining =isTraining\n        \n        # build top fc layers (Embedding that we are looking at testing time to represent the entire image)\n        if self.use_fc:\n            self.dropout = nn.Dropout(0.2)\n            self.fc = nn.Linear(in_features,fc_dim )\n            self.bn = nn.BatchNorm1d(fc_dim)\n            self.init_params()\n            in_features = fc_dim\n        self.loss_fn = loss_fn\n        if self.loss_fn=='softmax':\n            self.final = nn.Linear(in_features, CFG.classes)\n        elif self.loss_fn =='ArcFace':\n            self.final = ArcFaceModule( in_features,\n                                        CFG.classes,\n                                        scale = 30,\n                                        margin = 0.5,\n                                        easy_margin = False,\n                                        ls_eps = 0.0)\n            \n    def forward(self, image, label):\n        features = self.get_features(image)\n        if self.isTraining:\n            logits = self.final(features, label)\n            return logits\n        else:\n            return features\n    \n    def init_params(self):\n        nn.init.xavier_normal_(self.fc.weight)\n        nn.init.constant_(self.fc.bias,0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n        \n        \n    def get_features(self,inp):\n        batch_dim = inp.shape[0]\n        inp = self.backbone(inp)\n        inp = self.pooling(inp).view(batch_dim, -1)\n        if self.use_fc and self.isTraining:\n            inp = self.dropout(inp)\n            inp = self.fc(inp)\n            inp = self.bn(inp)\n            \n        return inp\n    \n    \n# shoppe_label_classfier = ShopeeLabelGroupClassfier()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = '../input/shopee-product-matching/train_images'\nTEST_DIR = '../input/shopee-product-matching/test_images'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get Text Embeddings","metadata":{}},{"cell_type":"code","source":"def get_text_embeddings(df_cu, max_features = 15000, n_components = 5000):\n    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n    pca = PCA(n_components = n_components)\n    text_embeddings = pca.fit_transform(text_embeddings).get()\n    print(f'Our title text embedding shape is {text_embeddings.shape}')\n    del model, pca\n    gc.collect()\n    return text_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get Image Embeddings","metadata":{}},{"cell_type":"code","source":"def get_image_embeddings(data, root_dir, model_path = CFG.model_path_arcface):\n    embeds = []\n    \n    model = ShopeeEncoderBackBone1()\n#     model = ShopeeLabelGroupClassfier()\n    model.load_state_dict(torch.load(model_path))\n    model = model.to(CFG.device)\n    model.eval()\n    \n    data_aug = get_test_transforms()\n    \n    image_dataset = ShopeeDataset(data, root_dir, isTraining=False, transform = data_aug)\n\n    image_loader = torch.utils.data.DataLoader(\n        image_dataset,\n        batch_size=CFG.batch_size,\n        pin_memory=True,\n        drop_last=False\n    )\n    \n    \n    with torch.no_grad():\n        for img,label in tqdm(image_loader): \n            img = img.cuda()\n            label = label.cuda()\n            feat = model(img,label)\n            image_embeddings = feat.detach().cpu().numpy()\n            embeds.append(image_embeddings)\n    \n    \n    del model\n    image_embeddings = np.concatenate(embeds)\n    print(f'Our image embeddings shape is {image_embeddings.shape}')\n    del embeds\n    gc.collect()\n    return image_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get Top k Neighbors","metadata":{}},{"cell_type":"code","source":"def get_neighbors(df, embeddings, KNN = 50, isImage=False, metric_param = 'cosine'):\n    print(embeddings.shape)\n    model = NearestNeighbors(n_neighbors = KNN,metric=metric_param)\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    print(distances.shape)\n    if not CFG.isTesting:\n        \n        # we will use different threshold for neighbor retrieval, basically we also want to make threashold smaller \n        # to retrieval small number of records because we have testing image size around 70000 huge memory constraint\n        if isImage:\n            thresholds = list(np.arange(0.01, 4,0.5))\n        else:\n            thresholds = list(np.arange(0.1, 1, 0.1))\n        scores = []\n        # for each threshold get top k neighbors with in threshold distance \n        # then get f1 score\n        for threshold in thresholds:\n            predictions = []\n            for k in range(embeddings.shape[0]):\n                idx = np.where(distances[k,] < threshold)[0]\n                ids = indices[k,idx]\n                # get posting ids based on retrival set\n                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n                predictions.append(posting_ids)\n            df['pred_matches'] = predictions\n            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n            score = df['f1'].mean()\n            print(f'Our f1 score for threshold {threshold} is {score}')\n            scores.append(score)\n        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n        best_threshold = max_score['thresholds'].values[0]\n        best_score = max_score['scores'].values[0]\n        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n        \n        # Use threshold\n        predictions = []\n        print(\"for training time\")\n        for k in range(embeddings.shape[0]):\n            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n            if isImage:\n#                 print(\"choosing 0.2\")\n                idx = np.where(distances[k,] < best_threshold)[0]\n            else:\n                idx = np.where(distances[k,] < best_threshold)[0]\n            ids = indices[k,idx]\n            posting_ids = df['posting_id'].iloc[ids].values\n            predictions.append(posting_ids)\n    \n    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n    else:\n        predictions = []\n        for k in tqdm(range(embeddings.shape[0])):\n            if isImage:\n                # testing for different threshold after submission\n#                 idx = np.where(distances[k,] < 0.21 )[0]\n                idx = np.where(distances[k,] < 0.3 )[0]\n            else:\n#                 idx = np.where(distances[k,] < 0.30)[0]\n                idx = np.where(distances[k,] < 0.17)[0]\n            ids = indices[k,idx]\n            posting_ids = df['posting_id'].iloc[ids].values\n            predictions.append(posting_ids)\n        \n    del model, distances, indices\n    gc.collect()\n    return df, predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing for submission","metadata":{}},{"cell_type":"code","source":"# get dataset\ndf,df_cu = read_dataset()\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_dir = None\nif CFG.isTesting:\n    _dir = TEST_DIR\nelse:\n    _dir = TRAIN_DIR","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get image Embeddings \nimage_embeddings = get_image_embeddings(df,_dir )\nnp.save(\"image_embeddings_0.9_training\",image_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get text Embeddings\ntext_embeddings = get_text_embeddings(df_cu, max_features = 15000, n_components = 5000)\nnp.save(\"text_embeddings_0.9_training\",text_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get image model predictions\ndf,image_predictions = get_neighbors(df, image_embeddings, KNN = 50, isImage = True, metric_param='cosine')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df, text_predictions = get_neighbors(df, text_embeddings, KNN = 50, isImage=False,metric_param='cosine')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_predictions(row):\n    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n    return ' '.join( np.unique(x) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Test_config:\n    isText=True,\n    isImage=True\n    \n    \ndef combine_predictions_conditional(row):\n    if Test_config.isImage and Test_config.isText:\n        x = np.concatenate([row['image_predictions'], row['text_predictions']])\n    elif Test_config.isImage:\n        x = np.concatenate([row['image_predictions'], row['image_predictions']])\n    else:\n        x = np.concatenate([row['text_predictions'], row['text_predictions']])\n    return ' '.join( np.unique(x) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For cv and testing\nif not CFG.isTesting:\n    df['image_predictions'] = image_predictions\n    df['text_predictions'] = text_predictions\n    df['pred_matches'] = df.apply(combine_predictions_conditional, axis = 1)\n    df['f1'] = f1_score(df['matches'], df['pred_matches'])\n    score = df['f1'].mean()\n    print(f'Our final f1 cv score is for Text and Image Model {score}')\n    df['matches'] = df['pred_matches']\n    df[['posting_id', 'matches']].to_csv('submission_0.9_cosine_textTh_0.17_imageTh_0.3_both_text_image.csv', index = False)\n    \n    ## doing only for images\n    df['image_predictions'] = image_predictions\n    df['text_predictions'] = text_predictions\n    Test_config.isImage = True\n    Test_config.isText=False\n    df['pred_matches'] = df.apply(combine_predictions_conditional, axis = 1)\n    df['f1'] = f1_score(df['matches'], df['pred_matches'])\n    score = df['f1'].mean()\n    print(f'Our final f1 cv score is for Image Model {score}')\n    df['matches'] = df['pred_matches']\n    df[['posting_id', 'matches']].to_csv('submission_0.9_cosine_imageTh_0.3_only_image.csv', index = False)\n    \n    ## doing only for Text\n    df['image_predictions'] = image_predictions\n    df['text_predictions'] = text_predictions\n    Test_config.isImage = False\n    Test_config.isText=True\n    df['pred_matches'] = df.apply(combine_predictions_conditional, axis = 1)\n    df['f1'] = f1_score(df['matches'], df['pred_matches'])\n    score = df['f1'].mean()\n    print(f'Our final f1 cv score is for Text Model {score}')\n    df['matches'] = df['pred_matches']\n    df[['posting_id', 'matches']].to_csv('submission_0.9_cosine_textTh_0.17_only_text.csv', index = False)\nelse:\n    df['image_predictions'] = image_predictions\n    df['text_predictions'] = text_predictions\n    df['matches'] = df.apply(combine_predictions_conditional, axis = 1)\n    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}